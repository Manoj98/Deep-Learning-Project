#  Efficacy of Machine Generated Annotations
Code Project Files for CSE 8803 - DLT Deep Learning for Text 

# Efficacy of Machine Generated Annotations

## Authors
- Anshit Verma
- Manoj Parmar
- Palash Choudhary
- Samaksh Gulati

## Project Overview
This project investigates the use of synthetic labels generated by GPT-3 for fine-tuning language models (LLMs) to reduce the resource overhead associated with human-annotated labels. The study explores the performance of synthetic labels in comparison to human labels and demonstrates the cost-effectiveness of using machine-generated annotations.

## Problem Statement
Creating high-quality instruction-tuning datasets from scratch is resource-intensive. This project aims to:
- Distill instruction fine-tuning data from closed-source models to reduce resource overhead.
- Evaluate the efficacy of synthetic labels generated by GPT-3 for text classification tasks.

## Motivation
Recent advancements in NLP have shown that fine-tuning language models on datasets described via instructions substantially improves zero-shot performance on unseen tasks. However, generating these datasets is costly. This project explores the potential of using synthetic labels to alleviate this issue.

## Data
- **Source**: Research paper titles and conference names.
- **Dataset Size**: 2507 research paper titles across 5 conferences.
- **Class Imbalance**: Majority class comprises 34.5% of records.

## Methodology
1. **Classification via GPT-3**:
   - Generate class labels using GPT-3 with zero-shot training for validation set.
   - Evaluate performance by calculating classification accuracy.
2. **Fine-tuning BERT with Human Annotated Data**:
   - Fine-tune pre-trained BERT model with labeled training data.
   - Use the fine-tuned model to classify validation data and measure performance.
3. **Fine-tuning BERT with GPT Annotated Data**:
   - Generate training data labels using GPT-3 through instructional tuning.
   - Fine-tune pre-trained BERT model with GPT annotated labeled data.
   - Use the fine-tuned model to classify validation data and measure performance.

## Results
- **Accuracy of GPT-3 Annotations**: 78.54%
- **Model Performance**:
  - Methodology 1 (GPT-3 zero-shot): 78.25% F1-score
  - Methodology 2 (Human annotated): 82.8% F1-score
  - Methodology 3 (GPT-3 annotated): 79.5% F1-score

## Key Takeaways
- GPT-3 generated labels show a minor performance drop compared to human labels (4% decrease in F1-score).
- The cost of human annotation is nearly 795 times higher than GPT-3 generated labels.
- GPT-3 annotations provide a cost-effective alternative with comparable performance, especially useful in resource-constrained scenarios.

## Future Work
- Experimentation with open-source generative models such as LLaMA 7B.
- Testing variations of the BERT model.
- Applying the methodology to more complex datasets.
- Exploring domain adaptation fine-tuning.

## References
1. Wei J., Bosma M., Zhao V. Y., et al. (2021). Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.
2. Wang Y., Kordi Y., Mishra S., et al. (2022). Self-instruct: Aligning language model with self-generated instructions. arXiv preprint arXiv:2212.10560.
3. Alpaca: Stanford CRFM (2023). [Link](https://crfm.stanford.edu/2023/03/13/alpaca.html)
4. Ouyang L., Wu J., Jiang X., et al. (2022). Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35, pp. 27730-27744.

## Acknowledgements
We would like to thank our colleagues and mentors who provided invaluable feedback and support throughout this project.
